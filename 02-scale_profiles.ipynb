{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be632b06-464f-469d-b245-d018824f54ef",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4f4387-771e-4eaf-aca1-c1152f1897fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "import geodata\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db8b4c4-f7a3-489e-8b07-ab8ce5f2fcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82632118-ead8-4efc-b950-3c00c1f33432",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0889ceca-ebd8-4b3a-8af0-907a97425ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"2030\"\n",
    "charging_power = 11\n",
    "cluster = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e2c7d-f7a5-48f2-9719-ff5ccba6bd28",
   "metadata": {},
   "source": [
    "# Reading Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5900d6ae-35dc-437c-be44-22dbc16b0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ev_population.pickle', 'rb') as f:\n",
    "    ev_population = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da11f94-0851-4a93-a555-ee1e8a4df0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLZ_Gemeinde</th>\n",
       "      <th>KKZ</th>\n",
       "      <th>2020</th>\n",
       "      <th>2025</th>\n",
       "      <th>2030</th>\n",
       "      <th>2035</th>\n",
       "      <th>2040</th>\n",
       "      <th>2045</th>\n",
       "      <th>2050</th>\n",
       "      <th>Gemeinde</th>\n",
       "      <th>PLZ</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Typ_differenziert</th>\n",
       "      <th>Profil</th>\n",
       "      <th>NUTS3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54298</th>\n",
       "      <th>54298  AACH</th>\n",
       "      <td>7211</td>\n",
       "      <td>7.838229</td>\n",
       "      <td>68.057259</td>\n",
       "      <td>188.480445</td>\n",
       "      <td>349.229940</td>\n",
       "      <td>478.115967</td>\n",
       "      <td>545.521333</td>\n",
       "      <td>573.087811</td>\n",
       "      <td>AACH</td>\n",
       "      <td>54298</td>\n",
       "      <td>Landgemeinde</td>\n",
       "      <td>Landgemeinde</td>\n",
       "      <td>[HT6]</td>\n",
       "      <td>DEB25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78267</th>\n",
       "      <th>78267  AACH,ST.</th>\n",
       "      <td>8335</td>\n",
       "      <td>23.522947</td>\n",
       "      <td>177.387925</td>\n",
       "      <td>480.778145</td>\n",
       "      <td>877.060477</td>\n",
       "      <td>1187.826308</td>\n",
       "      <td>1347.949286</td>\n",
       "      <td>1412.966666</td>\n",
       "      <td>AACH</td>\n",
       "      <td>78267</td>\n",
       "      <td>Größere Kleinstadt</td>\n",
       "      <td>Größere Kleinstadt</td>\n",
       "      <td>[HT5]</td>\n",
       "      <td>DE138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52062</th>\n",
       "      <th>52062  AACHEN, STADT</th>\n",
       "      <td>5334</td>\n",
       "      <td>1577.645762</td>\n",
       "      <td>11648.828673</td>\n",
       "      <td>31459.283476</td>\n",
       "      <td>57240.093137</td>\n",
       "      <td>77382.428026</td>\n",
       "      <td>87735.184826</td>\n",
       "      <td>91933.922371</td>\n",
       "      <td>AACHEN</td>\n",
       "      <td>52062</td>\n",
       "      <td>Großstadt</td>\n",
       "      <td>Kleinere Großstadt</td>\n",
       "      <td>[HT1, HT2]</td>\n",
       "      <td>DEA2D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PLZ_Gemeinde                 KKZ         2020          2025          2030  \\\n",
       "54298 54298  AACH           7211     7.838229     68.057259    188.480445   \n",
       "78267 78267  AACH,ST.       8335    23.522947    177.387925    480.778145   \n",
       "52062 52062  AACHEN, STADT  5334  1577.645762  11648.828673  31459.283476   \n",
       "\n",
       "PLZ_Gemeinde                        2035          2040          2045  \\\n",
       "54298 54298  AACH             349.229940    478.115967    545.521333   \n",
       "78267 78267  AACH,ST.         877.060477   1187.826308   1347.949286   \n",
       "52062 52062  AACHEN, STADT  57240.093137  77382.428026  87735.184826   \n",
       "\n",
       "PLZ_Gemeinde                        2050 Gemeinde    PLZ                 Typ  \\\n",
       "54298 54298  AACH             573.087811     AACH  54298        Landgemeinde   \n",
       "78267 78267  AACH,ST.        1412.966666     AACH  78267  Größere Kleinstadt   \n",
       "52062 52062  AACHEN, STADT  91933.922371   AACHEN  52062           Großstadt   \n",
       "\n",
       "PLZ_Gemeinde                 Typ_differenziert      Profil  NUTS3  \n",
       "54298 54298  AACH                 Landgemeinde       [HT6]  DEB25  \n",
       "78267 78267  AACH,ST.       Größere Kleinstadt       [HT5]  DE138  \n",
       "52062 52062  AACHEN, STADT  Kleinere Großstadt  [HT1, HT2]  DEA2D  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_population.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc89bfd-5b44-4867-9423-36ce5e0fbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"output/export_sc\" + scenario  + \"_cp\" + str(charging_power) + \"_cluster\" + str(cluster) + \".xlsx\"\n",
    "\n",
    "# Read the DataFrames from different sheets\n",
    "profiles_all = pd.read_excel(file_path, sheet_name='load', index_col=0, header=[0,1,2,3])\n",
    "pos_flex = pd.read_excel(file_path, sheet_name='pos_flex', index_col=0, header=[0,1,2,3])\n",
    "neg_flex = pd.read_excel(file_path, sheet_name='neg_flex', index_col=0, header=[0,1,2,3])\n",
    "driving = pd.read_excel(file_path, sheet_name='driving', index_col=0, header=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756762a3-e175-4911-8980-3d04847b1bcf",
   "metadata": {},
   "source": [
    "## Profile Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "151b6dba-db71-4ec3-8609-78d05757002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_charging_location_new = {}\n",
    "dict_share_at_home = {}\n",
    "dict_share_at_home[\"Landgemeinde\"]         = .90\n",
    "dict_share_at_home[\"Kleine Kleinstadt\"]    = .87\n",
    "dict_share_at_home[\"Größere Kleinstadt\"]   = .83\n",
    "dict_share_at_home[\"Kleinere Mittelstadt\"] = .72\n",
    "dict_share_at_home[\"Größere Mittelstadt\"]  = .78\n",
    "dict_share_at_home[\"Kleinere Großstadt\"]   = .62\n",
    "dict_share_at_home[\"Große Großstadt\"]      = .42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b1f473-8558-40f6-bbab-e1ef40ef3aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in dict_share_at_home:\n",
    "    dict_charging_location_new[loc] = {}\n",
    "    for charge in [\"Arbeitsplatz_Öffentlich\",\"Arbeitsplatz_Zuhause\",\"Zuhause\",\"Arbeitsplatz_Zuhause_Öffentlich\",\"Arbeitsplatz\",\"Öffentlich\",\"Zuhause_Öffentlich\"]:\n",
    "        if charge in [\"Arbeitsplatz\",\"Öffentlich\",\"Arbeitsplatz_Öffentlich\"]: \n",
    "            dict_charging_location_new[loc][charge] = (1-dict_share_at_home[loc])/3\n",
    "        else: \n",
    "            dict_charging_location_new[loc][charge] = (dict_share_at_home[loc])/4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c93ad8-26a9-487f-9a12-5dab194b32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5a01c9e-2c59-4380-9d5e-cdaae620bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:925: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time:  1403.3924469947815\n"
     ]
    }
   ],
   "source": [
    "if generate:\n",
    "    start = time.time()\n",
    "     \n",
    "    # dictionary for each region\n",
    "    regions_profiles = {}\n",
    "    regions_neg_flex = {}\n",
    "    regions_pos_flex = {}\n",
    "    regions_driving = {}\n",
    "\n",
    "    # define considered years\n",
    "    years = [int(scenario)]\n",
    "\n",
    "    # iterate each region\n",
    "    for region in ev_population.index:\n",
    "        regions_profiles[region] = {}\n",
    "        regions_neg_flex[region] = {}\n",
    "        regions_pos_flex[region] = {}\n",
    "        regions_driving[region] = {}\n",
    "        # iterate each year\n",
    "        for year in years:\n",
    "            regions_profiles[region][year] = {}\n",
    "            regions_neg_flex[region][year] = {}\n",
    "            regions_pos_flex[region][year] = {}\n",
    "            regions_driving[region][year] = {}\n",
    "            # iterate day of week\n",
    "            for day in [\"Wochentag\",\"Wochenende\"]:\n",
    "                # initialize empty container for each region and time series\n",
    "                regions_profiles[region][year][day]            = profiles_all.loc[:,(ev_population.loc[region,\"Typ_differenziert\"],day,\"Arbeitsplatz_Zuhause_Öffentlich\")].copy()\n",
    "                regions_neg_flex[region][year][day]            = neg_flex.loc[:,(ev_population.loc[region,\"Typ_differenziert\"],day,\"Arbeitsplatz_Zuhause_Öffentlich\")].copy()\n",
    "                regions_pos_flex[region][year][day]            = pos_flex.loc[:,(ev_population.loc[region,\"Typ_differenziert\"],day,\"Arbeitsplatz_Zuhause_Öffentlich\")].copy()\n",
    "                regions_driving[region][year][day]             = driving.loc[:,(ev_population.loc[region,\"Typ_differenziert\"],day,\"Arbeitsplatz_Zuhause_Öffentlich\")].copy()\n",
    "                regions_profiles[region][year][day].loc[:,:]   = 0\n",
    "                regions_neg_flex[region][year][day].loc[:,:]   = 0\n",
    "                regions_pos_flex[region][year][day].loc[:,:]   = 0\n",
    "                regions_driving[region][year][day].loc[:,:]    = 0\n",
    "                \n",
    "                # sum by all charging location\n",
    "                for charging_location in dict_charging_location_new[ev_population.loc[region,\"Typ_differenziert\"]]:\n",
    "                    # add profile to container\n",
    "                    regions_profiles[region][year][day] +=     profiles_all.loc[:,(ev_population.loc[region,\"Typ_differenziert\"],day,charging_location)] * ev_population.loc[region,year] * dict_charging_location_new[ev_population.loc[region,\"Typ_differenziert\"]][charging_location] \n",
    "                    regions_driving[region][year][day]  +=     driving.loc[:,(ev_population.loc[region,\"Typ_differenziert\"],day,charging_location)] * ev_population.loc[region,year] * dict_charging_location_new[ev_population.loc[region,\"Typ_differenziert\"]][charging_location] \n",
    "                \n",
    "                # sum only by charging location with home charging\n",
    "                for charging_location in pos_flex.columns.get_level_values(2).drop_duplicates():     \n",
    "                    regions_pos_flex[region][year][day] +=     pos_flex.loc[:,(ev_population.loc[region,\"Typ_differenziert\"],day,charging_location)] * ev_population.loc[region,year] * dict_charging_location_new[ev_population.loc[region,\"Typ_differenziert\"]][charging_location] \n",
    "                    regions_neg_flex[region][year][day] +=     neg_flex.loc[:,(ev_population.loc[region,\"Typ_differenziert\"],day,charging_location)] * ev_population.loc[region,year] * dict_charging_location_new[ev_population.loc[region,\"Typ_differenziert\"]][charging_location] \n",
    "    \n",
    "    with open('data/regions_profiles_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(regions_profiles, f)\n",
    "    with open('data/regions_pos_flex_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(regions_pos_flex, f)\n",
    "    with open('data/regions_neg_flex_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(regions_neg_flex, f)\n",
    "    with open('data/regions_driving_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(regions_driving, f)\n",
    "    \n",
    "    # measure runtime        \n",
    "    end = time.time()\n",
    "    print(\"Elapsed Time: \", end - start)\n",
    "    \n",
    "else:\n",
    "    with open('data/regions_profiles_{}.pickle'.format(scenario), 'rb') as f:\n",
    "        regions_profiles = pickle.load(f)\n",
    "    with open('data/regions_pos_flex_{}.pickle'.format(scenario), 'rb') as f:\n",
    "        regions_pos_flex = pickle.load(f)\n",
    "    with open('data/regions_neg_flex_{}.pickle'.format(scenario), 'rb') as f:\n",
    "        regions_neg_flex = pickle.load(f)\n",
    "    with open('data/regions_driving_{}.pickle'.format(scenario), 'rb') as f:\n",
    "        regions_driving = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f26b62-64cf-4632-b426-dece0a2f3cda",
   "metadata": {},
   "source": [
    "## Relabel Regions (PLZ to NUTS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf436c03-de99-474f-888a-c5828d0572b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "relabel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b14d4680-55e7-4dd2-ad9b-b107625f71c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following regions were not found in the nuts_to_plz:\n",
      "('06922', '06922  ANNABURG,STADT')\n",
      "('99437', '99437  BAD BERKA,STADT')\n",
      "('37534', '37534  Bad Grund (Harz)')\n",
      "('09227', '09227  BURKHARDTSDORF')\n",
      "('03007', '03007  COTTBUS')\n",
      "('08439', '08439  CRIMMITSCHAU, STADT')\n",
      "('06813', '06813  DESSAU-ROßLAU')\n",
      "('01827', '01827  DUERRROEHRSDORF-DITTERSBACH')\n",
      "('37547', '37547  EINBECK, STADT')\n",
      "('04445', '04445  GROSSPOESNA')\n",
      "('79683', '79683  KLEINES WIESENTAL')\n",
      "('07558', '07558  KRAFTSDORF')\n",
      "('31097', '31097  Lamspringe')\n",
      "('08312', '08312  LAUTER-BERNSBACH, STADT')\n",
      "('04007', '04007  LEIPZIG')\n",
      "('09238', '09238  LICHTENAU')\n",
      "('08146', '08146  LICHTENSTEIN/SA., STADT')\n",
      "('08399', '08399  LIMBACH-OBERFROHNA, STADT')\n",
      "('24875', '24875  MITTELANGELN')\n",
      "('64743', '64743  Oberzent, Stadt')\n",
      "('02744', '02744  ODERWITZ')\n",
      "('04460', '04460  PEGAU, STADT')\n",
      "('04657', '04657  PENIG, STADT')\n",
      "('82243', '82243  POECKING')\n",
      "('16921', '16921  PRITZWALK, STADT')\n",
      "('04448', '04448  RACKWITZ')\n",
      "('65423', '65423  RUESSELSHEIM,ST.')\n",
      "('04430', '04430  SCHKEUDITZ, STADT')\n",
      "('38385', '38385  Söllingen')\n",
      "('25868', '25868  Stapel')\n",
      "('08318', '08318  STUETZENGRUEN')\n",
      "('83359', '83359  SURBERG')\n",
      "('09380', '09380  THALHEIM/ERZGEB., STADT')\n",
      "('08121', '08121  WILDENFELS, STADT')\n",
      "('94155', '94155  WINDORF,M.')\n",
      "('27632', '27632  Wurster Nordseeküste')\n",
      "('14627', '14627  WUSTERMARK')\n",
      "Elapsed Time:  99.50805139541626\n"
     ]
    }
   ],
   "source": [
    "if relabel:\n",
    "    start = time.time()\n",
    "    \n",
    "    #change labels\n",
    "    nuts_to_plz = pd.read_csv(\"data//nuts3ToPlz.csv\",delimiter=\";\")\n",
    "\n",
    "    nuts_dict_profiles = {}\n",
    "    nuts_dict_pos_flex = {}\n",
    "    nuts_dict_neg_flex = {}\n",
    "    nuts_dict_driving = {}\n",
    "    print(\"The following regions were not found in the nuts_to_plz:\")\n",
    "    for region in ev_population.index:\n",
    "        if np.any(nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values): \n",
    "            ev_population.loc[region[0],\"NUTS3\"] = nuts_to_plz.loc[nuts_to_plz[\"CODE\"]==int(region[0]),\"NUTS3\"].values[0]\n",
    "            \n",
    "            if nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0] not in nuts_dict_profiles.keys():\n",
    "                nuts_dict_profiles[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]] = {}\n",
    "                nuts_dict_profiles[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]][\"list\"] = []\n",
    "                nuts_dict_pos_flex[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]] = {}\n",
    "                nuts_dict_pos_flex[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]][\"list\"] = []\n",
    "                nuts_dict_neg_flex[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]] = {}\n",
    "                nuts_dict_neg_flex[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]][\"list\"] = []\n",
    "                nuts_dict_driving[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]] = {}\n",
    "                nuts_dict_driving[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]][\"list\"] = []\n",
    "            \n",
    "            nuts_dict_profiles[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]][\"list\"].append(regions_profiles[region])            \n",
    "            nuts_dict_pos_flex[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]][\"list\"].append(regions_pos_flex[region])\n",
    "            nuts_dict_neg_flex[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]][\"list\"].append(regions_neg_flex[region])\n",
    "            nuts_dict_driving[nuts_to_plz[nuts_to_plz[\"CODE\"]==int(region[0])][\"NUTS3\"].values[0]][\"list\"].append(regions_driving[region])\n",
    "        else: print(region)\n",
    "            \n",
    "    for region in nuts_dict_profiles:\n",
    "        nuts_dict_profiles[region][int(scenario)] = {}                                                                                                          \n",
    "        nuts_dict_pos_flex[region][int(scenario)] = {}\n",
    "        nuts_dict_neg_flex[region][int(scenario)] = {}\n",
    "        nuts_dict_driving[region][int(scenario)] = {}\n",
    "        for day in [\"Wochentag\",\"Wochenende\"]:\n",
    "            nuts_dict_profiles[region][int(scenario)][day] = sum([i[int(scenario)][day] for i in nuts_dict_profiles[region][\"list\"]])\n",
    "            nuts_dict_pos_flex[region][int(scenario)][day] = sum([i[int(scenario)][day] for i in nuts_dict_pos_flex[region][\"list\"]])\n",
    "            nuts_dict_neg_flex[region][int(scenario)][day] = sum([i[int(scenario)][day] for i in nuts_dict_neg_flex[region][\"list\"]])\n",
    "            nuts_dict_driving[region][int(scenario)][day] = sum([i[int(scenario)][day] for i in nuts_dict_driving[region][\"list\"]])\n",
    "            \n",
    "        nuts_dict_profiles[region].pop('list', None)\n",
    "        nuts_dict_pos_flex[region].pop('list', None)\n",
    "        nuts_dict_neg_flex[region].pop('list', None)\n",
    "        nuts_dict_driving[region].pop('list', None)\n",
    "        \n",
    "    # The sum of the charging profiles for a day must be equal to the sum of the driving profile for that day\n",
    "    for key1 in nuts_dict_driving.keys():\n",
    "        for key2 in  nuts_dict_driving[key1].keys():\n",
    "            for key3 in  nuts_dict_driving[key1][key2].keys():\n",
    "                for c in nuts_dict_driving[key1][key2][key3].columns:\n",
    "                    fac = sum(nuts_dict_profiles[key1][key2][key3].loc[:,c]) / sum(nuts_dict_driving[key1][key2][key3].loc[:,c])\n",
    "                    if math.isnan(fac):\n",
    "                        fac = 1\n",
    "                    nuts_dict_driving[key1][key2][key3].loc[:,c] = nuts_dict_driving[key1][key2][key3].loc[:,c] * fac    \n",
    "                    \n",
    "    with open('data/nuts_profiles_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(nuts_dict_profiles, f)                                                                                                              \n",
    "    with open('data/nuts_pos_flex_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(nuts_dict_pos_flex, f)\n",
    "    with open('data/nuts_neg_flex_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(nuts_dict_neg_flex, f)\n",
    "    with open('data/ev_population.pickle', 'wb') as f:\n",
    "        pickle.dump(ev_population, f)\n",
    "    with open('data/nuts_driving_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(nuts_dict_driving, f)\n",
    "\n",
    "    # measure runtime        \n",
    "    end = time.time()\n",
    "    print(\"Elapsed Time: \", end - start)\n",
    "    \n",
    "else:\n",
    "    with open('data/nuts_profiles_{}.pickle'.format(scenario), 'rb') as f:\n",
    "        nuts_dict_profiles = pickle.load(f)\n",
    "    with open('data/nuts_pos_flex_{}.pickle'.format(scenario), 'rb') as f:\n",
    "        nuts_dict_pos_flex = pickle.load(f)\n",
    "    with open('data/nuts_neg_flex_{}.pickle'.format(scenario), 'rb') as f:\n",
    "        nuts_dict_neg_flex = pickle.load(f)\n",
    "    with open('data/ev_population.pickle', 'rb') as f:\n",
    "        ev_population = pickle.load(f)\n",
    "    with open('data/nuts_driving{}.pickle'.format(scenario), 'rb') as f:\n",
    "        nuts_dict_driving = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e6bb8-bc66-4b9f-9657-560e551e17e3",
   "metadata": {},
   "source": [
    "## Relabel regions (PLZ to Siedlungstypen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d160d26-bd9d-452b-986a-8135634f651f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folgende Regionen wurden in der nuts_to_plz nicht gefunden:\n",
      "('06922', '06922  ANNABURG,STADT')\n",
      "('99437', '99437  BAD BERKA,STADT')\n",
      "('37534', '37534  Bad Grund (Harz)')\n",
      "('09227', '09227  BURKHARDTSDORF')\n",
      "('03007', '03007  COTTBUS')\n",
      "('08439', '08439  CRIMMITSCHAU, STADT')\n",
      "('06813', '06813  DESSAU-ROßLAU')\n",
      "('01827', '01827  DUERRROEHRSDORF-DITTERSBACH')\n",
      "('37547', '37547  EINBECK, STADT')\n",
      "('04445', '04445  GROSSPOESNA')\n",
      "('79683', '79683  KLEINES WIESENTAL')\n",
      "('07558', '07558  KRAFTSDORF')\n",
      "('31097', '31097  Lamspringe')\n",
      "('08312', '08312  LAUTER-BERNSBACH, STADT')\n",
      "('04007', '04007  LEIPZIG')\n",
      "('09238', '09238  LICHTENAU')\n",
      "('08146', '08146  LICHTENSTEIN/SA., STADT')\n",
      "('08399', '08399  LIMBACH-OBERFROHNA, STADT')\n",
      "('24875', '24875  MITTELANGELN')\n",
      "('64743', '64743  Oberzent, Stadt')\n",
      "('02744', '02744  ODERWITZ')\n",
      "('04460', '04460  PEGAU, STADT')\n",
      "('04657', '04657  PENIG, STADT')\n",
      "('82243', '82243  POECKING')\n",
      "('16921', '16921  PRITZWALK, STADT')\n",
      "('04448', '04448  RACKWITZ')\n",
      "('65423', '65423  RUESSELSHEIM,ST.')\n",
      "('04430', '04430  SCHKEUDITZ, STADT')\n",
      "('38385', '38385  Söllingen')\n",
      "('25868', '25868  Stapel')\n",
      "('08318', '08318  STUETZENGRUEN')\n",
      "('83359', '83359  SURBERG')\n",
      "('09380', '09380  THALHEIM/ERZGEB., STADT')\n",
      "('08121', '08121  WILDENFELS, STADT')\n",
      "('94155', '94155  WINDORF,M.')\n",
      "('27632', '27632  Wurster Nordseeküste')\n",
      "('14627', '14627  WUSTERMARK')\n",
      "Elapsed Time:  113.63153982162476\n"
     ]
    }
   ],
   "source": [
    "relabel2 = True\n",
    "if relabel2:\n",
    "    start = time.time()\n",
    "    \n",
    "    # change labels\n",
    "    nuts_to_plz = pd.read_csv(\"data//nuts3ToPlz.csv\", delimiter=\";\")\n",
    "\n",
    "    siedlungstyp_dict_profiles = {}\n",
    "    siedlungstyp_dict_pos_flex = {}\n",
    "    siedlungstyp_dict_neg_flex = {}\n",
    "    siedlungstyp_dict_driving = {}\n",
    "    print(\"The following regions were not found in the nuts_to_plz:\")\n",
    "    \n",
    "    for region in ev_population.index:\n",
    "        if np.any(nuts_to_plz[nuts_to_plz[\"CODE\"] == int(region[0])][\"NUTS3\"].values):\n",
    "            if ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0] not in siedlungstyp_dict_profiles.keys():\n",
    "                siedlungstyp_dict_profiles[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]] = {}\n",
    "                siedlungstyp_dict_profiles[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]][\"list\"] = []\n",
    "                siedlungstyp_dict_pos_flex[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]] = {}\n",
    "                siedlungstyp_dict_pos_flex[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]][\"list\"] = []\n",
    "                siedlungstyp_dict_neg_flex[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]] = {}\n",
    "                siedlungstyp_dict_neg_flex[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]][\"list\"] = []\n",
    "                siedlungstyp_dict_driving[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]] = {}\n",
    "                siedlungstyp_dict_driving[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]][\"list\"] = []\n",
    "\n",
    "            # Profiles according to settlement type\n",
    "            siedlungstyp_dict_profiles[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]][\"list\"].append(regions_profiles[region])\n",
    "            siedlungstyp_dict_pos_flex[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]][\"list\"].append(regions_pos_flex[region])\n",
    "            siedlungstyp_dict_neg_flex[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]][\"list\"].append(regions_neg_flex[region])\n",
    "            siedlungstyp_dict_driving[ev_population[ev_population[\"PLZ\"] == region[0]][\"Typ\"].values[0]][\"list\"].append(regions_driving[region])\n",
    "\n",
    "        else:\n",
    "            print(region)\n",
    "    \n",
    "    for typ in siedlungstyp_dict_profiles:\n",
    "        siedlungstyp_dict_profiles[typ][int(scenario)] = {}\n",
    "        siedlungstyp_dict_pos_flex[typ][int(scenario)] = {}\n",
    "        siedlungstyp_dict_neg_flex[typ][int(scenario)] = {}\n",
    "        siedlungstyp_dict_driving[typ][int(scenario)] = {}\n",
    "        for day in [\"Wochentag\", \"Wochenende\"]:\n",
    "            siedlungstyp_dict_profiles[typ][int(scenario)][day] = sum([i[int(scenario)][day] for i in siedlungstyp_dict_profiles[typ][\"list\"]])\n",
    "            siedlungstyp_dict_pos_flex[typ][int(scenario)][day] = sum([i[int(scenario)][day] for i in siedlungstyp_dict_pos_flex[typ][\"list\"]])\n",
    "            siedlungstyp_dict_neg_flex[typ][int(scenario)][day] = sum([i[int(scenario)][day] for i in siedlungstyp_dict_neg_flex[typ][\"list\"]])\n",
    "            siedlungstyp_dict_driving[typ][int(scenario)][day] = sum([i[int(scenario)][day] for i in siedlungstyp_dict_driving[typ][\"list\"]])\n",
    "\n",
    "        siedlungstyp_dict_profiles[typ].pop('list', None)\n",
    "        siedlungstyp_dict_pos_flex[typ].pop('list', None)\n",
    "        siedlungstyp_dict_neg_flex[typ].pop('list', None)\n",
    "        siedlungstyp_dict_driving[typ].pop('list', None)\n",
    "        \n",
    "    # The sum of the charging profiles for a day must be equal to the sum of the driving profile for that day\n",
    "    for key1 in siedlungstyp_dict_driving.keys():\n",
    "        for key2 in siedlungstyp_dict_driving[key1].keys():\n",
    "            for key3 in siedlungstyp_dict_driving[key1][key2].keys():\n",
    "                for c in siedlungstyp_dict_driving[key1][key2][key3].columns:\n",
    "                    fac = sum(siedlungstyp_dict_profiles[key1][key2][key3].loc[:,c]) / sum(siedlungstyp_dict_driving[key1][key2][key3].loc[:,c])\n",
    "                    if math.isnan(fac):\n",
    "                        fac = 1\n",
    "                    siedlungstyp_dict_driving[key1][key2][key3].loc[:,c] = siedlungstyp_dict_driving[key1][key2][key3].loc[:,c] * fac\n",
    "\n",
    "    with open('data/siedlungstyp_profiles_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(siedlungstyp_dict_profiles, f)\n",
    "    with open('data/siedlungstyp_pos_flex_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(siedlungstyp_dict_pos_flex, f)\n",
    "    with open('data/siedlungstyp_neg_flex_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(siedlungstyp_dict_neg_flex, f)\n",
    "    with open('data/siedlungstyp_driving_{}.pickle'.format(scenario), 'wb') as f:\n",
    "        pickle.dump(siedlungstyp_dict_driving, f)\n",
    "\n",
    "    # measure runtime\n",
    "    end = time.time()\n",
    "    print(\"Elapsed Time: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc75d9-44b6-405f-a880-0b5bbaec367c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Concate Years (for NUTS3 and settlement types)\n",
    "All steps above must already have been carried out for all years selected below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c3f1841-8402-48c9-897f-d2c7713b1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2030]\n",
    "concate_focus_years = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea60e90e-9333-42fb-8b09-829580ca2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "if concate_focus_years:\n",
    "    X_nuts_profiles = {}\n",
    "    X_siedlungstyp_profiles = {}\n",
    "    X_nuts_pos_flex = {}\n",
    "    X_siedlungstyp_pos_flex = {}\n",
    "    X_nuts_neg_flex = {}\n",
    "    X_siedlungstyp_neg_flex = {}\n",
    "    X_nuts_driving = {}\n",
    "    X_siedlungstyp_driving = {}\n",
    "\n",
    "    for year in years:\n",
    "\n",
    "        # all charging X_profiles \n",
    "        with open('data/nuts_profiles_{}.pickle'.format(year), 'rb') as f:\n",
    "            nuts_profiles = pickle.load(f)\n",
    "        with open('data/siedlungstyp_profiles_{}.pickle'.format(year), 'rb') as f:\n",
    "            siedlungstyp_profiles = pickle.load(f)\n",
    "        \n",
    "        # pos flex X_profiles \n",
    "        with open('data/nuts_pos_flex_{}.pickle'.format(year), 'rb') as f:\n",
    "            nuts_pos_flex = pickle.load(f)\n",
    "        with open('data/siedlungstyp_pos_flex_{}.pickle'.format(year), 'rb') as f:\n",
    "            siedlungstyp_pos_flex = pickle.load(f)\n",
    "\n",
    "        # neg flex X_profiles \n",
    "        with open('data/nuts_neg_flex_{}.pickle'.format(year), 'rb') as f:\n",
    "            nuts_neg_flex = pickle.load(f)\n",
    "        with open('data/siedlungstyp_neg_flex_{}.pickle'.format(year), 'rb') as f:\n",
    "            siedlungstyp_neg_flex = pickle.load(f)\n",
    "        \n",
    "        # driving X_profiles \n",
    "        with open('data/nuts_driving_{}.pickle'.format(year), 'rb') as f:\n",
    "            nuts_driving= pickle.load(f)\n",
    "        with open('data/siedlungstyp_driving_{}.pickle'.format(year), 'rb') as f:\n",
    "            siedlungstyp_driving = pickle.load(f)\n",
    "\n",
    "        # do it for all nuts3 regions\n",
    "        \"\"\"!!!\"\"\"\n",
    "        for i in nuts_profiles:\n",
    "            if i not in X_nuts_pos_flex.keys():\n",
    "                X_nuts_profiles[i] = {}\n",
    "                X_nuts_pos_flex[i] = {}\n",
    "                X_nuts_neg_flex[i] = {}\n",
    "                X_nuts_driving[i] = {}\n",
    "\n",
    "            X_nuts_profiles[i][year]  = nuts_profiles[i][year]\n",
    "            X_nuts_pos_flex[i][year]  = nuts_pos_flex[i][year]\n",
    "            X_nuts_neg_flex[i][year]  = nuts_neg_flex[i][year]\n",
    "            X_nuts_driving[i][year]  = nuts_driving[i][year]\n",
    "            \n",
    "        # do it for all settlement types\n",
    "        \"\"\"!!!\"\"\"\n",
    "        for i in siedlungstyp_profiles:\n",
    "            if i not in X_siedlungstyp_profiles.keys():\n",
    "                X_siedlungstyp_profiles[i] = {}\n",
    "                X_siedlungstyp_pos_flex[i] = {}\n",
    "                X_siedlungstyp_neg_flex[i] = {}\n",
    "                X_siedlungstyp_driving[i] = {}\n",
    "                \n",
    "            X_siedlungstyp_profiles[i][year]  = siedlungstyp_profiles[i][year]\n",
    "            X_siedlungstyp_pos_flex[i][year]  = siedlungstyp_pos_flex[i][year]\n",
    "            X_siedlungstyp_neg_flex[i][year]  = siedlungstyp_neg_flex[i][year]\n",
    "            X_siedlungstyp_driving[i][year]  = siedlungstyp_driving[i][year]\n",
    "    \n",
    "    # transfer to MW for nuts3\n",
    "    X_nuts_profiles  = {area:{year:{day:values/1000 for day,values in days.items()} for year,days in years.items()} for area,years in X_nuts_profiles.items()}\n",
    "    X_nuts_pos_flex  = {area:{year:{day:values/1000 for day,values in days.items()} for year,days in years.items()} for area,years in X_nuts_pos_flex.items()}\n",
    "    X_nuts_neg_flex  = {area:{year:{day:values/1000 for day,values in days.items()} for year,days in years.items()} for area,years in X_nuts_neg_flex.items()}\n",
    "    X_nuts_driving  = {area:{year:{day:values/1000 for day,values in days.items()} for year,days in years.items()} for area,years in X_nuts_driving.items()}\n",
    "    \n",
    "    # transfer to MW for Siedlungstypen\n",
    "    X_siedlungstyp_profiles  = {area:{year:{day:values/1000 for day,values in days.items()} for year,days in years.items()} for area,years in X_siedlungstyp_profiles.items()}\n",
    "    X_siedlungstyp_pos_flex  = {area:{year:{day:values/1000 for day,values in days.items()} for year,days in years.items()} for area,years in X_siedlungstyp_pos_flex.items()}\n",
    "    X_siedlungstyp_neg_flex  = {area:{year:{day:values/1000 for day,values in days.items()} for year,days in years.items()} for area,years in X_siedlungstyp_neg_flex.items()}\n",
    "    X_siedlungstyp_driving  = {area:{year:{day:values/1000 for day,values in days.items()} for year,days in years.items()} for area,years in X_siedlungstyp_driving.items()}\n",
    "    \n",
    "    # Save for NUTS3\n",
    "    with open('data/X_nuts_profiles.pickle', 'wb') as f:\n",
    "        pickle.dump(X_nuts_profiles, f)\n",
    "    with open('data/X_nuts_pos_flex.pickle', 'wb') as f:\n",
    "        pickle.dump(X_nuts_pos_flex, f)\n",
    "    with open('data/X_nuts_neg_flex.pickle', 'wb') as f:\n",
    "        pickle.dump(X_nuts_neg_flex, f)\n",
    "    with open('data/X_nuts_driving.pickle', 'wb') as f:\n",
    "        pickle.dump(X_nuts_driving, f)\n",
    "        \n",
    "    # Save for settlement types\n",
    "    with open('data/X_siedlungstyp_profiles.pickle', 'wb') as f:\n",
    "        pickle.dump(X_siedlungstyp_profiles, f)\n",
    "    with open('data/X_siedlungstyp_pos_flex.pickle', 'wb') as f:\n",
    "        pickle.dump(X_siedlungstyp_pos_flex, f)\n",
    "    with open('data/X_siedlungstyp_neg_flex.pickle', 'wb') as f:\n",
    "        pickle.dump(X_siedlungstyp_neg_flex, f)\n",
    "    with open('data/X_siedlungstyp_driving.pickle', 'wb') as f:\n",
    "        pickle.dump(X_siedlungstyp_driving, f)\n",
    "else:\n",
    "    \n",
    "    # Load for NUTS3\n",
    "    with open('data/X_nuts_profiles.pickle', 'rb') as f:\n",
    "        X_nuts_profiles = pickle.load(f)\n",
    "    with open('data/X_nuts_pos_flex.pickle', 'rb') as f:\n",
    "        X_nuts_pos_flex = pickle.load(f)\n",
    "    with open('data/X_nuts_neg_flex.pickle', 'rb') as f:\n",
    "        X_nuts_neg_flex = pickle.load(f)  \n",
    "    with open('data/X_nuts_driving.pickle', 'rb') as f:\n",
    "        X_nuts_driving = pickle.load(f)  \n",
    "    \n",
    "    # Load for NUTS3\n",
    "    with open('data/X_siedlungstyp_profiles.pickle', 'rb') as f:\n",
    "        X_siedlungstyp_profiles = pickle.load(f)\n",
    "    with open('data/X_siedlungstyp_pos_flex.pickle', 'rb') as f:\n",
    "        X_siedlungstyp_pos_flex = pickle.load(f)\n",
    "    with open('data/X_siedlungstyp_neg_flex.pickle', 'rb') as f:\n",
    "        X_siedlungstyp_neg_flex = pickle.load(f)  \n",
    "    with open('data/X_siedlungstyp_driving.pickle', 'rb') as f:\n",
    "        X_siedlungstyp_driving = pickle.load(f)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
