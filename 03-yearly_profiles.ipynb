{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23379907-19f2-4db5-b182-aea236a06155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "import geodata\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import date, datetime, timedelta\n",
    "from functions import calc_easter\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "028bfed0-446b-42c3-8ffb-5d515e7b6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL SETTINGS\n",
    "xl_engine = \"openpyxl\"\n",
    "#input_path_base = pdir_folder\n",
    "ref_w_year = 2015\n",
    "ref_c_year = 2015\n",
    "leap_year = \"cutdec31\"\n",
    "\n",
    "# YEARS\n",
    "years_list = [2030]\n",
    "utc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d790d75c-2999-42b1-a58f-ad6709d48673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of clusters!\n",
    "clusters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a02b2f-1b7f-48ba-8e81-21d09c8e2d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read region-specific ev load profiles and shift potential.\n"
     ]
    }
   ],
   "source": [
    "print(\"Read region-specific ev load profiles and shift potential.\")\n",
    "dict_profiles = pd.read_pickle(\"data/X_nuts_profiles.pickle\")\n",
    "dict_neg_flex = pd.read_pickle(\"data/X_nuts_neg_flex.pickle\")\n",
    "dict_pos_flex = pd.read_pickle(\"data/X_nuts_pos_flex.pickle\")\n",
    "dict_driving = pd.read_pickle(\"data/X_nuts_driving.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a7db20-aba9-451f-975b-0d55340f5c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Siedlungstyp-specific ev load profiles and shift potential.\n"
     ]
    }
   ],
   "source": [
    "print(\"Read Siedlungstyp-specific ev load profiles and shift potential.\")\n",
    "dict_profiles_Siedlungstyp = pd.read_pickle(\"data/X_siedlungstyp_profiles.pickle\")\n",
    "dict_neg_flex_Siedlungstyp = pd.read_pickle(\"data/X_siedlungstyp_neg_flex.pickle\")\n",
    "dict_pos_flex_Siedlungstyp = pd.read_pickle(\"data/X_siedlungstyp_pos_flex.pickle\")\n",
    "dict_driving_Siedlungstyp = pd.read_pickle(\"data/X_siedlungstyp_driving.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d01b94e-6550-41a9-8836-e40e3f37616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEB25', 'DE138', 'DEA2D', 'DE11D', 'DE71D']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get regions\n",
    "nutsList = list(dict_profiles)\n",
    "nutsList[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b421e07-7f24-453b-87f8-52ea65ad2d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Landgemeinde',\n",
       " 'Größere Kleinstadt',\n",
       " 'Großstadt',\n",
       " 'Mittelstadt',\n",
       " 'Kleine Kleinstadt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiedlungstypList = list(dict_profiles_Siedlungstyp.keys())\n",
    "SiedlungstypList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61abb1c4-e5e8-4de8-b8e6-0ae82acdba9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change 2020 to 2019, as 2019 is the key for the other data\n",
    "if 2020 in years_list:\n",
    "    for nested_d in dict_profiles.values():\n",
    "        nested_d[2019] = nested_d.pop(2020)\n",
    "    for nested_d in dict_neg_flex.values():\n",
    "        nested_d[2019] = nested_d.pop(2020)\n",
    "    for nested_d in dict_pos_flex.values():\n",
    "        nested_d[2019] = nested_d.pop(2020)\n",
    "    for nested_d in dict_driving.values():\n",
    "        nested_d[2019] = nested_d.pop(2020)\n",
    "    # do the same for Siedlungstypen\n",
    "    for nested_d in dict_profiles_Siedlungstyp.values():\n",
    "        nested_d[2019] = nested_d.pop(2020)\n",
    "    for nested_d in dict_neg_flex_Siedlungstyp.values():\n",
    "        nested_d[2019] = nested_d.pop(2020)\n",
    "    for nested_d in dict_pos_flex_Siedlungstyp.values():\n",
    "        nested_d[2019] = nested_d.pop(2020)\n",
    "    for nested_d in dict_driving_Siedlungstyp.values():\n",
    "        nested_d[2019] = nested_d.pop(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a215c31-9ed2-4095-83d8-e3fff90c1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate yearly charging profiles per region and charging type\n",
    "# Generate dataframe for calendar year:\n",
    "leap_years = [1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020]\n",
    "      \n",
    "# this is a day longer than necessary so that mez time can be cut out later\n",
    "utc_w = pd.date_range(start=\"01/01/\"+str(ref_w_year), end=\"01/02/\"+str(ref_w_year+1), freq=\"H\")[:-1].strftime('%Y-%m-%d %H:%M:%S')\n",
    "utc_c = pd.date_range(start=\"01/01/\"+str(ref_c_year), end=\"01/02/\"+str(ref_c_year+1), freq=\"H\")[:-1].strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "if ref_w_year in leap_years:\n",
    "    if leap_year == \"cutdec31\":\n",
    "        utc_w = utc_w[~utc_w.str.contains(\"12-31\")]\n",
    "    elif leap_year == \"cutfeb29\":\n",
    "        utc_w = utc_w[~utc_w.str.contains(\"02-29\")]\n",
    "    \n",
    "if ref_c_year in leap_years:\n",
    "    if leap_year == \"cutdec31\":\n",
    "        utc_c = utc_c[~utc_c.str.contains(\"12-31\")]\n",
    "    elif leap_year == \"cutfeb29\":\n",
    "        utc_c = utc_c[~utc_c.str.contains(\"02-29\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ea353f0-9b6f-4b4a-80ed-574ffea83a26",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Feiertage.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10968\\3803118588.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdate_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDayTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# MEZ dates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdate_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Wochentag\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Werktag\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"Samstag\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"Sonntag\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdate_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweekday\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mholidays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/Feiertage.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mholidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_c_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholidays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Monat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholidays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Tag\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mholidays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Tag\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Monat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mholidates\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_c_year\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_c_year\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 )\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Feiertage.xlsx'"
     ]
    }
   ],
   "source": [
    "# time is mez\n",
    "mez_c = pd.to_datetime(pd.to_datetime(utc_c)+timedelta(days=0, hours=1)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "DayTable = pd.DataFrame(index=sorted(list(set([d[:-9] for d in mez_c])))[:-1])\n",
    "if ref_c_year in leap_years:\n",
    "    if leap_year == \"cutdec31\":\n",
    "        DayTable = DayTable[~DayTable.index.str.contains(\"12-31\")]\n",
    "    elif leap_year == \"cutfeb29\":\n",
    "        DayTable = DayTable[~DayTable.index.str.contains(\"02-29\")]\n",
    "\n",
    "date_df = pd.DataFrame(index=pd.to_datetime(DayTable.index))  # MEZ dates\n",
    "date_df[\"Wochentag\"] = [\"Werktag\" if i <= 4 else \"Samstag\" if i == 5 else \"Sonntag\" for i in date_df.index.weekday]\n",
    "holidays = pd.read_excel(\"data/Feiertage.xlsx\")\n",
    "holidates = [dt.date(ref_c_year, int(holidays.loc[i,\"Monat\"]), int(holidays.loc[i,\"Tag\"])) for i in holidays[[\"Tag\", \"Monat\"]].dropna().index]\n",
    "holidates += [dt.date(ref_c_year-1, 12, 31), dt.date(ref_c_year+1, 1, 1)]\n",
    "easter = calc_easter(ref_c_year)\n",
    "holidates += [easter+timedelta(holidays['Tage nach Ostersonntag'].loc[i]) for i in holidays[['Tage nach Ostersonntag']].dropna().index]\n",
    "date_df[\"Wochentag\"] = [date_df[\"Wochentag\"].loc[i] if not i in holidates else \"Sonntag\" for i in date_df.index]\n",
    "date_df[\"season\"] = [\"So-\" if (i>=date(ref_c_year,5,15) and i<=date(ref_c_year,9,14)) else \"Wi-\" for i in date_df.index]\n",
    "date_df[\"Profiltag\"] = [date_df[\"season\"].loc[i]+date_df[\"Wochentag\"].loc[i] for i in date_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9f2dc-f4ba-4825-924f-e57f390f2497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if there are columns missing\n",
    "for reg in nutsList:\n",
    "    for y in years_list:\n",
    "        for d in list(['Wochentag', 'Wochenende']):\n",
    "            for i in range(clusters):\n",
    "                if i not in dict_pos_flex[reg][y][d]:\n",
    "                    print(\" not existing: pos_flex\", reg, y, d, i)\n",
    "                    dict_pos_flex[reg][y][d][i] = 0 \n",
    "                if i not in dict_neg_flex[reg][y][d]:\n",
    "                    print(\" not existing: neg_flex\", reg, y, d, i)\n",
    "                    dict_neg_flex[reg][y][d][i] = 0\n",
    "                if i not in dict_profiles[reg][y][d]:\n",
    "                    print(\" not existing: profile\", reg, y, d, i)\n",
    "                    dict_profiles[reg][y][d][i] = 0\n",
    "                if i not in dict_driving[reg][y][d]:\n",
    "                    print(\" not existing: driving\", reg, y, d, i)\n",
    "                    dict_driving[reg][y][d][i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a37dcc-b38f-40e9-bea9-4bc3d92d874e",
   "metadata": {},
   "source": [
    "# Calculating Profiles for variable number of clusters\n",
    "Way down below you can also find the old code, where the cluster size was hardcoded to 8. I only slightly changed that code.\n",
    "\n",
    "Directly following is the code without hardcoding that should work for every \"clusters\" value. I changed much more in this code compared to arnoldfs original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e1f53ca-cdf6-45bb-9725-1606ed8203b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation of yearly charging profiles for each Siedlungstyp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:17<00:00,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save profiles to pickle\n",
      "Save pos flex potential to pickle\n",
      "Save neg flex potential to pickle\n",
      "Save driving to pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate Profiles for Siedlungstypen\n",
    "\"\"\"\n",
    "\n",
    "dict_profiles_daily_Siedlungstyp = {}\n",
    "dict_pos_flex_daily_Siedlungstyp = {}\n",
    "dict_neg_flex_daily_Siedlungstyp = {}\n",
    "dict_driving_daily_Siedlungstyp = {}\n",
    "print(\"Generation of yearly charging profiles for each Siedlungstyp\")\n",
    "for reg in tqdm(SiedlungstypList):\n",
    "    dict_profiles_daily_Siedlungstyp[reg] = {}\n",
    "    dict_pos_flex_daily_Siedlungstyp[reg] = {}\n",
    "    dict_neg_flex_daily_Siedlungstyp[reg] = {}\n",
    "    dict_driving_daily_Siedlungstyp[reg] = {}\n",
    "    for y in years_list:\n",
    "        profiles_Siedlungstyp = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles_Siedlungstyp[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
    "                                     }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n",
    "                                 else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles_Siedlungstyp[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n",
    "        pos_flex_Siedlungstyp = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_pos_flex_Siedlungstyp[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
    "                                     }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n",
    "                                 else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_pos_flex_Siedlungstyp[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n",
    "        neg_flex_Siedlungstyp = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_neg_flex_Siedlungstyp[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
    "                                     }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n",
    "                                 else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_neg_flex_Siedlungstyp[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n",
    "        driving_Siedlungstyp = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_driving_Siedlungstyp[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
    "                                     }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n",
    "                                 else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_driving_Siedlungstyp[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n",
    "\n",
    "        profiles_Siedlungstyp_df = pd.DataFrame(columns=[\"time\"] + list(range(clusters)))\n",
    "        pos_flex_Siedlungstyp_df = pd.DataFrame(columns=[\"time\"] + list(range(clusters)))\n",
    "        neg_flex_Siedlungstyp_df = pd.DataFrame(columns=[\"time\"] + list(range(clusters)))\n",
    "        driving_Siedlungstyp_df = pd.DataFrame(columns=[\"time\"] + list(range(clusters)))\n",
    "\n",
    "        for d in pos_flex_Siedlungstyp:\n",
    "            profiles_Siedlungstyp_df = pd.concat([profiles_Siedlungstyp_df, profiles_Siedlungstyp[d]])\n",
    "            pos_flex_Siedlungstyp_df = pd.concat([pos_flex_Siedlungstyp_df, pos_flex_Siedlungstyp[d]])\n",
    "            neg_flex_Siedlungstyp_df = pd.concat([neg_flex_Siedlungstyp_df, neg_flex_Siedlungstyp[d]])\n",
    "            driving_Siedlungstyp_df = pd.concat([driving_Siedlungstyp_df, driving_Siedlungstyp[d]])\n",
    "\n",
    "        profiles_Siedlungstyp_df = profiles_Siedlungstyp_df.set_index(\"time\", drop=True)\n",
    "        pos_flex_Siedlungstyp_df = pos_flex_Siedlungstyp_df.set_index(\"time\", drop=True)\n",
    "        neg_flex_Siedlungstyp_df = neg_flex_Siedlungstyp_df.set_index(\"time\", drop=True)\n",
    "        driving_Siedlungstyp_df = driving_Siedlungstyp_df.set_index(\"time\", drop=True)\n",
    "\n",
    "        profiles_Siedlungstyp_df[\"utc_c\"] = pd.to_datetime(pd.to_datetime(profiles_Siedlungstyp_df.index)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        pos_flex_Siedlungstyp_df[\"utc_c\"] = pd.to_datetime(pd.to_datetime(pos_flex_Siedlungstyp_df.index)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        neg_flex_Siedlungstyp_df[\"utc_c\"] = pd.to_datetime(pd.to_datetime(neg_flex_Siedlungstyp_df.index)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        driving_Siedlungstyp_df[\"utc_c\"] = pd.to_datetime(pd.to_datetime(driving_Siedlungstyp_df.index)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "        if utc:\n",
    "            profiles_Siedlungstyp_df = profiles_Siedlungstyp_df[profiles_Siedlungstyp_df.utc_c.str.contains(str(ref_c_year))]\n",
    "            profiles_Siedlungstyp_df = profiles_Siedlungstyp_df.set_index(\"utc_c\")\n",
    "            \n",
    "            pos_flex_Siedlungstyp_df = pos_flex_Siedlungstyp_df[pos_flex_Siedlungstyp_df.utc_c.str.contains(str(ref_c_year))]\n",
    "            pos_flex_Siedlungstyp_df = pos_flex_Siedlungstyp_df.set_index(\"utc_c\")\n",
    "            \n",
    "            neg_flex_Siedlungstyp_df = neg_flex_Siedlungstyp_df[neg_flex_Siedlungstyp_df.utc_c.str.contains(str(ref_c_year))]\n",
    "            neg_flex_Siedlungstyp_df = neg_flex_Siedlungstyp_df.set_index(\"utc_c\")\n",
    "            \n",
    "            driving_Siedlungstyp_df = driving_Siedlungstyp_df[driving_Siedlungstyp_df.utc_c.str.contains(str(ref_c_year))]\n",
    "            driving_Siedlungstyp_df = driving_Siedlungstyp_df.set_index(\"utc_c\")\n",
    "\n",
    "        else:\n",
    "            profiles_Siedlungstyp_df.index = profiles_Siedlungstyp_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            profiles_Siedlungstyp_df = profiles_Siedlungstyp_df[profiles_Siedlungstyp_df.index.str.contains(str(ref_c_year))]\n",
    "            profiles_Siedlungstyp_df = profiles_Siedlungstyp_df.drop([\"utc_c\"], axis=1)\n",
    "\n",
    "            pos_flex_Siedlungstyp_df.index = pos_flex_Siedlungstyp_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            pos_flex_Siedlungstyp_df = pos_flex_Siedlungstyp_df[pos_flex_Siedlungstyp_df.index.str.contains(str(ref_c_year))]\n",
    "            pos_flex_Siedlungstyp_df = pos_flex_Siedlungstyp_df.drop([\"utc_c\"], axis=1)\n",
    "            \n",
    "            neg_flex_Siedlungstyp_df.index = neg_flex_Siedlungstyp_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            neg_flex_Siedlungstyp_df = neg_flex_Siedlungstyp_df[neg_flex_Siedlungstyp_df.index.str.contains(str(ref_c_year))]\n",
    "            neg_flex_Siedlungstyp_df = neg_flex_Siedlungstyp_df.drop([\"utc_c\"], axis=1)\n",
    "            \n",
    "            driving_Siedlungstyp_df.index = driving_Siedlungstyp_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            driving_Siedlungstyp_df = driving_Siedlungstyp_df[driving_Siedlungstyp_df.index.str.contains(str(ref_c_year))]\n",
    "            driving_Siedlungstyp_df = driving_Siedlungstyp_df.drop([\"utc_c\"], axis=1)\n",
    "\n",
    "        dict_profiles_daily_Siedlungstyp[reg][y] = profiles_Siedlungstyp_df\n",
    "        dict_pos_flex_daily_Siedlungstyp[reg][y] = pos_flex_Siedlungstyp_df\n",
    "        dict_neg_flex_daily_Siedlungstyp[reg][y] = neg_flex_Siedlungstyp_df\n",
    "        dict_driving_daily_Siedlungstyp[reg][y] = driving_Siedlungstyp_df\n",
    "                          \n",
    "\n",
    "# Save results\n",
    "print(\"Save profiles to pickle\")\n",
    "with open(\"data/profiles_daily_Siedlungstyp_clusters\" + str(clusters) + \".pickle\", 'wb') as file:\n",
    "    pickle.dump(dict_profiles_daily_Siedlungstyp, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Save pos flex potential to pickle\")\n",
    "with open(\"data/pos_flex_daily_Siedlungstyp_clusters\" + str(clusters) + \".pickle\", 'wb') as file:\n",
    "    pickle.dump(dict_pos_flex_daily_Siedlungstyp, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Save neg flex potential to pickle\")\n",
    "with open(\"data/neg_flex_daily_Siedlungstyp_clusters\" + str(clusters) + \".pickle\", 'wb') as file:\n",
    "    pickle.dump(dict_neg_flex_daily_Siedlungstyp, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Save driving to pickle\")\n",
    "with open(\"data/driving_daily_Siedlungstyp_clusters\" + str(clusters) + \".pickle\", 'wb') as file:\n",
    "    pickle.dump(dict_driving_daily_Siedlungstyp, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "105f2748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458871.89244046854\n",
      "458871.8924404718\n"
     ]
    }
   ],
   "source": [
    "print(sum(dict_profiles_daily_Siedlungstyp[\"Großstadt\"][2030].loc[:,7]))\n",
    "print(sum(dict_driving_daily_Siedlungstyp[\"Großstadt\"][2030].loc[:,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddc7ca18-1cb4-487c-8756-9857a1e9b58c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation of yearly charging profiles for each NUTS region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 184/394 [10:37<12:07,  3.47s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10968\\1766464346.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mdict_driving_daily\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0myears_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         profiles = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles[reg][y]['Wochentag'][i] for i in range(clusters)}\n\u001b[0m\u001b[0;32m     18\u001b[0m                                      }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n\u001b[0;32m     19\u001b[0m                     else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10968\\1766464346.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m         profiles = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles[reg][y]['Wochentag'][i] for i in range(clusters)}\n\u001b[0;32m     18\u001b[0m                                      }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n\u001b[1;32m---> 19\u001b[1;33m                     else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         pos_flex = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_pos_flex[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10968\\1766464346.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m         profiles = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles[reg][y]['Wochentag'][i] for i in range(clusters)}\n\u001b[0;32m     18\u001b[0m                                      }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n\u001b[1;32m---> 19\u001b[1;33m                     else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         pos_flex = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_pos_flex[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3453\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3454\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3455\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate Profiles for NUTS3\n",
    "\"\"\"\n",
    "\n",
    "dict_profiles_daily = {}\n",
    "dict_pos_flex_daily = {}\n",
    "dict_neg_flex_daily = {}\n",
    "dict_driving_daily = {}\n",
    "print(\"Generation of yearly charging profiles for each NUTS region\")\n",
    "\n",
    "for reg in tqdm(nutsList):\n",
    "    dict_profiles_daily[reg] = {}\n",
    "    dict_pos_flex_daily[reg] = {}\n",
    "    dict_neg_flex_daily[reg] = {}\n",
    "    dict_driving_daily[reg] = {}\n",
    "    for y in years_list:\n",
    "        profiles = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
    "                                     }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n",
    "                    else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_profiles[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n",
    "        \n",
    "        pos_flex = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_pos_flex[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
    "                                     }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n",
    "                    else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_pos_flex[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n",
    "                    \n",
    "        neg_flex = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_neg_flex[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
    "                                     }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n",
    "                    else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_neg_flex[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n",
    "\n",
    "        driving = {d: pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_driving[reg][y]['Wochentag'][i] for i in range(clusters)}\n",
    "                                     }) if date_df[\"Wochentag\"].loc[d] == \"Werktag\"\n",
    "                    else pd.DataFrame({\"time\": pd.date_range(start=d, periods=24, freq=\"h\"), **{i: dict_driving[reg][y]['Wochenende'][i] for i in range(clusters)}}) for d in date_df.index}\n",
    "\n",
    "        \n",
    "        profiles_df = pd.DataFrame(columns=[\"time\"] + list(range(clusters)))\n",
    "        pos_flex_df = pd.DataFrame(columns=[\"time\"] + list(range(clusters)))\n",
    "        neg_flex_df = pd.DataFrame(columns=[\"time\"] + list(range(clusters)))\n",
    "        driving_df = pd.DataFrame(columns=[\"time\"] + list(range(clusters)))\n",
    "        \n",
    "        for d in pos_flex:\n",
    "            profiles_df = pd.concat([profiles_df, profiles[d]])\n",
    "            pos_flex_df = pd.concat([pos_flex_df, pos_flex[d]])\n",
    "            neg_flex_df = pd.concat([neg_flex_df, neg_flex[d]])\n",
    "            driving_df = pd.concat([driving_df, driving[d]])\n",
    "\n",
    "        profiles_df = profiles_df.set_index(\"time\", drop=True)\n",
    "        pos_flex_df = pos_flex_df.set_index(\"time\", drop=True)\n",
    "        neg_flex_df = neg_flex_df.set_index(\"time\", drop=True)\n",
    "        driving_df = driving_df.set_index(\"time\", drop=True)\n",
    "\n",
    "        profiles_df[\"utc_c\"] = pd.to_datetime(pd.to_datetime(profiles_df.index)).strftime(\n",
    "            '%Y-%m-%d %H:%M:%S')\n",
    "        pos_flex_df[\"utc_c\"] = pd.to_datetime(pd.to_datetime(pos_flex_df.index)).strftime(\n",
    "            '%Y-%m-%d %H:%M:%S')\n",
    "        neg_flex_df[\"utc_c\"] = pd.to_datetime(pd.to_datetime(neg_flex_df.index)).strftime(\n",
    "            '%Y-%m-%d %H:%M:%S')\n",
    "        driving_df[\"utc_c\"] = pd.to_datetime(pd.to_datetime(driving_df.index)).strftime(\n",
    "            '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        if utc:\n",
    "\n",
    "            profiles_df = profiles_df[profiles_df.utc_c.str.contains(str(ref_c_year))]\n",
    "            profiles_df = profiles_df.set_index(\"utc_c\")\n",
    "\n",
    "            pos_flex_df = pos_flex_df[pos_flex_df.utc_c.str.contains(str(ref_c_year))]\n",
    "            pos_flex_df = pos_flex_df.set_index(\"utc_c\")\n",
    "\n",
    "            neg_flex_df = neg_flex_df[neg_flex_df.utc_c.str.contains(str(ref_c_year))]\n",
    "            neg_flex_df = neg_flex_df.set_index(\"utc_c\")\n",
    "            \n",
    "            driving_df = driving_df[driving_df.utc_c.str.contains(str(ref_c_year))]\n",
    "            driving_df = driving_df.set_index(\"utc_c\")\n",
    "\n",
    "        else:\n",
    "            profiles_df.index = profiles_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            profiles_df = profiles_df[profiles_df.index.str.contains(str(ref_c_year))]\n",
    "            profiles_df = profiles_df.drop([\"utc_c\"], axis=1)\n",
    "\n",
    "            pos_flex_df.index = pos_flex_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            pos_flex_df = pos_flex_df[pos_flex_df.index.str.contains(str(ref_c_year))]\n",
    "            pos_flex_df = pos_flex_df.drop([\"utc_c\"], axis=1)\n",
    "\n",
    "            neg_flex_df.index = neg_flex_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            neg_flex_df = neg_flex_df[neg_flex_df.index.str.contains(str(ref_c_year))]\n",
    "            neg_flex_df = neg_flex_df.drop([\"utc_c\"], axis=1)\n",
    "            \n",
    "            driving_df.index = driving_df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            driving_df = driving_df[driving_df.index.str.contains(str(ref_c_year))]\n",
    "            driving_df = driving_df.drop([\"utc_c\"], axis=1)\n",
    "\n",
    "        dict_profiles_daily[reg][y] = profiles_df\n",
    "        dict_pos_flex_daily[reg][y] = pos_flex_df\n",
    "        dict_neg_flex_daily[reg][y] = neg_flex_df\n",
    "        dict_driving_daily[reg][y] = driving_df\n",
    "   \n",
    "\n",
    "# Save results\n",
    "print(\"Save profiles to pickle\")\n",
    "with open(\"data/profiles_daily_clusters\" + str(clusters) + \".pickle\", 'wb') as file:\n",
    "    pickle.dump(dict_profiles_daily, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Save pos flex potential to pickle\")\n",
    "with open(\"data/pos_flex_daily_clusters\" + str(clusters) + \".pickle\", 'wb') as file:\n",
    "    pickle.dump(dict_pos_flex_daily, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Save neg flex potential to pickle\")\n",
    "with open(\"data/neg_flex_daily_clusters\" + str(clusters) + \".pickle\", 'wb') as file:\n",
    "    pickle.dump(dict_neg_flex_daily, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "print(\"Save driving to pickle\")\n",
    "with open(\"data/driving_daily_clusters\" + str(clusters) + \".pickle\", 'wb') as file:\n",
    "    pickle.dump(dict_driving_daily, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d86865",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(dict_profiles_daily[\"DEB25\"][2030].loc[:,1]))\n",
    "print(sum(dict_driving_daily[\"DEB25\"][2030].loc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77d62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
